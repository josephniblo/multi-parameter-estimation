{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56f16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934814e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to force a full refresh of the data\n",
    "full_refresh = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702ac223",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = os.popen('git rev-parse --show-toplevel').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ec71d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2025-05-30--14h-02m-13s',\n",
       " '2025-05-30--14h-03m-06s',\n",
       " '2025-05-30--14h-04m-07s',\n",
       " '2025-05-30--14h-05m-08s',\n",
       " '2025-05-30--14h-19m-25s',\n",
       " '2025-05-30--14h-22m-01s',\n",
       " '2025-05-30--14h-24m-36s',\n",
       " '2025-05-30--14h-27m-02s',\n",
       " '2025-05-30--14h-43m-17s',\n",
       " '2025-05-30--14h-48m-08s',\n",
       " '2025-05-30--14h-52m-48s',\n",
       " '2025-05-30--14h-57m-52s']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = os.path.join(repo_root, 'multi-parameter-estimation', 'data')\n",
    "\n",
    "# Get list of data directories\n",
    "data_dirs = os.listdir(data_folder)\n",
    "data_dirs = [d for d in data_dirs if os.path.isdir(os.path.join(data_folder, d))]\n",
    "\n",
    "# skip old-data\n",
    "if 'old-data' in data_dirs:\n",
    "    data_dirs.remove('old-data')\n",
    "\n",
    "data_dirs.sort()\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c024a293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2025-05-30--14h-02m-13s',\n",
       " '2025-05-30--14h-03m-06s',\n",
       " '2025-05-30--14h-04m-07s',\n",
       " '2025-05-30--14h-05m-08s',\n",
       " '2025-05-30--14h-19m-25s',\n",
       " '2025-05-30--14h-22m-01s',\n",
       " '2025-05-30--14h-24m-36s',\n",
       " '2025-05-30--14h-27m-02s',\n",
       " '2025-05-30--14h-43m-17s',\n",
       " '2025-05-30--14h-48m-08s',\n",
       " '2025-05-30--14h-52m-48s',\n",
       " '2025-05-30--14h-57m-52s']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_dirs = data_dirs.copy()\n",
    "\n",
    "if not full_refresh:\n",
    "    for d in data_dirs:\n",
    "        if os.path.exists(os.path.join(data_folder, d, \"chunked_coincidences_n=200.csv\")):\n",
    "            new_data_dirs.remove(d)\n",
    "\n",
    "new_data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d18ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_dir</th>\n",
       "      <th>C</th>\n",
       "      <th>DB_H</th>\n",
       "      <th>DB_V</th>\n",
       "      <th>SB</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>0.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     data_dir    C  DB_H  DB_V   SB     N\n",
       "0     2025-05-30--14h-02m-13s  2.0  37.0   0.0  0.0  39.0\n",
       "1     2025-05-30--14h-02m-13s  0.0  39.0   0.0  0.0  39.0\n",
       "2     2025-05-30--14h-02m-13s  0.5  40.0   0.0  0.0  40.5\n",
       "3     2025-05-30--14h-02m-13s  1.0  38.0   0.0  0.0  39.0\n",
       "4     2025-05-30--14h-02m-13s  0.5  40.0   0.0  0.0  40.5\n",
       "...                       ...  ...   ...   ...  ...   ...\n",
       "1594  2025-05-30--14h-57m-52s  1.0  36.0   0.0  2.0  39.0\n",
       "1595  2025-05-30--14h-57m-52s  0.0  37.0   0.0  3.5  40.5\n",
       "1596  2025-05-30--14h-57m-52s  0.5  35.0   0.0  3.5  39.0\n",
       "1597  2025-05-30--14h-57m-52s  0.5  35.0   0.0  4.0  39.5\n",
       "1598  2025-05-30--14h-57m-52s  0.5  35.0   0.0  4.5  40.0\n",
       "\n",
       "[1599 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_chunks(data_dir):\n",
    "    if not os.path.exists(os.path.join(data_folder, data_dir, \"chunked_coincidences_n=40.csv\")):\n",
    "        print(f\"Skipping {data_dir} as it does not have the required file.\")\n",
    "        return pd.DataFrame()\n",
    "    coincidences = pd.read_csv(os.path.join(data_folder, data_dir, \"chunked_coincidences_n=40.csv\"))\n",
    "    coincidences[\"data_dir\"] = data_dir\n",
    "    return coincidences\n",
    "\n",
    "chunks_df = pd.concat([load_chunks(d) for d in new_data_dirs], ignore_index=True)\n",
    "chunks_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d701e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82808/345050552.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_80 = chunks_df.groupby('data_dir', group_keys=False).apply(lambda g: k_wise_sum(g, k=2)).reset_index(drop=True)\n",
      "/tmp/ipykernel_82808/345050552.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_120 = chunks_df.groupby('data_dir', group_keys=False).apply(lambda g: k_wise_sum(g, k=3)).reset_index(drop=True)\n",
      "/tmp/ipykernel_82808/345050552.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_160 = chunks_df.groupby('data_dir', group_keys=False).apply(lambda g: k_wise_sum(g, k=4)).reset_index(drop=True)\n",
      "/tmp/ipykernel_82808/345050552.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_200 = chunks_df.groupby('data_dir', group_keys=False).apply(lambda g: k_wise_sum(g, k=5)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_dir</th>\n",
       "      <th>C</th>\n",
       "      <th>DB_H</th>\n",
       "      <th>DB_V</th>\n",
       "      <th>SB</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>4.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>3.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>199.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>3.5</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-30--14h-02m-13s</td>\n",
       "      <td>3.5</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>3.5</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>200.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>2.5</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>199.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>5.5</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>3.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2025-05-30--14h-57m-52s</td>\n",
       "      <td>2.5</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>198.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    data_dir    C   DB_H  DB_V    SB      N\n",
       "0    2025-05-30--14h-02m-13s  4.0  194.0   0.0   0.0  198.0\n",
       "1    2025-05-30--14h-02m-13s  4.0  195.0   0.0   1.0  200.0\n",
       "2    2025-05-30--14h-02m-13s  3.0  195.0   0.0   1.5  199.5\n",
       "3    2025-05-30--14h-02m-13s  3.5  195.0   0.0   0.5  199.0\n",
       "4    2025-05-30--14h-02m-13s  3.5  196.0   0.0   0.5  200.0\n",
       "..                       ...  ...    ...   ...   ...    ...\n",
       "312  2025-05-30--14h-57m-52s  3.5  187.0   0.0  10.0  200.5\n",
       "313  2025-05-30--14h-57m-52s  2.5  186.0   0.0  11.0  199.5\n",
       "314  2025-05-30--14h-57m-52s  5.5  181.0   0.0  12.5  199.0\n",
       "315  2025-05-30--14h-57m-52s  3.0  187.0   0.0  11.0  201.0\n",
       "316  2025-05-30--14h-57m-52s  2.5  181.0   0.0  15.0  198.5\n",
       "\n",
       "[317 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns that are not needed\n",
    "def k_wise_sum(group, k):\n",
    "    # Drop last rows if not divisible by k\n",
    "    n = len(group) - (len(group) % k)\n",
    "    group = group.iloc[:n].reset_index(drop=True)\n",
    "    # Sum every k rows\n",
    "    kwise = group.groupby(group.index // k).sum()\n",
    "    # Restore data_dir from the first row of each group\n",
    "    kwise['data_dir'] = group['data_dir'].iloc[::k].values\n",
    "    return kwise\n",
    "\n",
    "# Example usage for k=3\n",
    "df_80 = chunks_df.groupby('data_dir', group_keys=False).apply(lambda g: k_wise_sum(g, k=2)).reset_index(drop=True)\n",
    "df_120 = chunks_df.groupby('data_dir', group_keys=False).apply(lambda g: k_wise_sum(g, k=3)).reset_index(drop=True)\n",
    "df_160 = chunks_df.groupby('data_dir', group_keys=False).apply(lambda g: k_wise_sum(g, k=4)).reset_index(drop=True)\n",
    "df_200 = chunks_df.groupby('data_dir', group_keys=False).apply(lambda g: k_wise_sum(g, k=5)).reset_index(drop=True)\n",
    "df_200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae418eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes to csv files\n",
    "# save the dataframes to csv files based on the data_dir\n",
    "for data_dir in new_data_dirs:\n",
    "    df_80_subset = df_80[df_80[\"data_dir\"] == data_dir]\n",
    "    df_120_subset = df_120[df_120[\"data_dir\"] == data_dir]\n",
    "    df_160_subset = df_160[df_160[\"data_dir\"] == data_dir]\n",
    "    df_200_subset = df_200[df_200[\"data_dir\"] == data_dir]\n",
    "    df_80_subset.to_csv(os.path.join(data_folder, data_dir, \"chunked_coincidences_n=80.csv\"), index=False)\n",
    "    df_120_subset.to_csv(os.path.join(data_folder, data_dir, \"chunked_coincidences_n=120.csv\"), index=False)\n",
    "    df_160_subset.to_csv(os.path.join(data_folder, data_dir, \"chunked_coincidences_n=160.csv\"), index=False)\n",
    "    df_200_subset.to_csv(os.path.join(data_folder, data_dir, \"chunked_coincidences_n=200.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
