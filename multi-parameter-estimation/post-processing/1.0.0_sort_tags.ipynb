{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d2d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17d26ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# White and blue output ports of the in-fibre beam splitters\n",
    "DETECTORS = {\n",
    "    9: {\"arm\": \"TT\", \"color\": \"white\"},\n",
    "    12: {\"arm\": \"TT\", \"color\": \"blue\"},\n",
    "    11: {\"arm\": \"TR\", \"color\": \"white\"},\n",
    "    10: {\"arm\": \"TR\", \"color\": \"blue\"},\n",
    "    1: {\"arm\": \"RT\", \"color\": \"white\"},\n",
    "    4: {\"arm\": \"RT\", \"color\": \"blue\"},\n",
    "    7: {\"arm\": \"RR\", \"color\": \"white\"},\n",
    "    2: {\"arm\": \"RR\", \"color\": \"blue\"},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2150892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = os.popen('git rev-parse --show-toplevel').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de20841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2025-06-02--17h-26m-50s',\n",
       " '2025-06-02--17h-38m-12s',\n",
       " '2025-06-02--17h-49m-29s',\n",
       " '2025-06-02--18h-01m-13s',\n",
       " '2025-06-02--18h-12m-39s',\n",
       " '2025-06-02--18h-24m-10s',\n",
       " '2025-06-02--18h-35m-26s',\n",
       " '2025-06-02--18h-47m-05s',\n",
       " '2025-06-02--18h-58m-36s',\n",
       " '2025-06-02--19h-10m-18s',\n",
       " '2025-06-02--19h-21m-45s',\n",
       " '2025-06-02--19h-33m-20s',\n",
       " '2025-06-02--19h-44m-43s',\n",
       " '2025-06-02--19h-56m-12s',\n",
       " '2025-06-02--20h-07m-18s',\n",
       " '2025-06-02--20h-18m-48s',\n",
       " '2025-06-02--20h-30m-44s',\n",
       " '2025-06-02--20h-42m-10s',\n",
       " '2025-06-02--20h-53m-30s',\n",
       " '2025-06-02--21h-05m-03s',\n",
       " '2025-06-02--21h-16m-30s',\n",
       " '2025-06-02--21h-28m-09s',\n",
       " '2025-06-02--21h-39m-42s',\n",
       " '2025-06-02--21h-51m-15s',\n",
       " '2025-06-02--22h-03m-02s',\n",
       " '2025-06-02--22h-14m-22s',\n",
       " '2025-06-02--22h-26m-08s',\n",
       " '2025-06-02--22h-37m-13s',\n",
       " '2025-06-02--22h-48m-52s',\n",
       " '2025-06-02--23h-00m-30s',\n",
       " '2025-06-02--23h-11m-57s',\n",
       " '2025-06-02--23h-23m-39s',\n",
       " '2025-06-02--23h-35m-12s',\n",
       " '2025-06-02--23h-46m-27s',\n",
       " '2025-06-02--23h-58m-30s',\n",
       " '2025-06-03--00h-09m-58s',\n",
       " '2025-06-03--00h-21m-14s',\n",
       " '2025-06-03--00h-32m-56s',\n",
       " '2025-06-03--00h-44m-23s',\n",
       " '2025-06-03--00h-55m-53s',\n",
       " '2025-06-03--01h-07m-14s',\n",
       " '2025-06-03--01h-18m-46s',\n",
       " '2025-06-03--01h-30m-35s',\n",
       " '2025-06-03--01h-42m-28s',\n",
       " '2025-06-03--01h-54m-10s',\n",
       " '2025-06-03--02h-05m-45s',\n",
       " '2025-06-03--02h-17m-27s',\n",
       " '2025-06-03--02h-28m-50s',\n",
       " '2025-06-03--02h-40m-20s',\n",
       " '2025-06-03--02h-52m-16s',\n",
       " '2025-06-03--03h-03m-54s',\n",
       " '2025-06-03--03h-15m-43s',\n",
       " '2025-06-03--03h-27m-22s',\n",
       " '2025-06-03--03h-38m-31s',\n",
       " '2025-06-03--03h-50m-11s',\n",
       " '2025-06-03--04h-01m-33s',\n",
       " '2025-06-03--04h-13m-12s',\n",
       " '2025-06-03--04h-24m-35s',\n",
       " '2025-06-03--04h-36m-07s',\n",
       " '2025-06-03--04h-47m-28s',\n",
       " '2025-06-03--04h-59m-06s',\n",
       " '2025-06-03--05h-10m-35s',\n",
       " '2025-06-03--05h-22m-26s',\n",
       " '2025-06-03--05h-33m-48s',\n",
       " '2025-06-03--05h-45m-32s',\n",
       " '2025-06-03--05h-57m-21s',\n",
       " '2025-06-03--06h-08m-57s',\n",
       " '2025-06-03--06h-20m-29s',\n",
       " '2025-06-03--06h-32m-17s',\n",
       " '2025-06-03--06h-43m-55s',\n",
       " '2025-06-03--06h-55m-50s',\n",
       " '2025-06-03--07h-07m-08s',\n",
       " '2025-06-03--07h-18m-44s',\n",
       " '2025-06-03--07h-30m-31s',\n",
       " '2025-06-03--07h-41m-54s']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = os.path.join(repo_root, 'multi-parameter-estimation', 'data')\n",
    "\n",
    "# Get list of data directories\n",
    "data_dirs = os.listdir(data_folder)\n",
    "data_dirs = [d for d in data_dirs if os.path.isdir(os.path.join(data_folder, d))]\n",
    "\n",
    "# skip old-data\n",
    "if 'old-data' in data_dirs:\n",
    "    data_dirs.remove('old-data')\n",
    "\n",
    "data_dirs.sort()\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f99c617",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'detector_a_time_tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_414153/2195708925.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m     coincidences[\u001b[33m\"data_dir\"\u001b[39m] = data_dir\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m coincidences\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m coincidences_df = pd.concat([load_coincidences(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;28;01min\u001b[39;00m data_dirs], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m coincidences_df = coincidences_df.sort_values(by=[\u001b[33m\"data_dir\"\u001b[39m, \u001b[33m\"detector_a_time_tag\"\u001b[39m])\n\u001b[32m      8\u001b[39m coincidences_df\n",
      "\u001b[32m~/Heriot-Watt University Team Dropbox/RES_EPS_EMQL/projects/multi-parameter-estimation/.venv/lib/python3.13/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7168\u001b[39m                 f\"Length of ascending ({len(ascending)})\"  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   7169\u001b[39m                 f\" != length of by ({len(by)})\"\n\u001b[32m   7170\u001b[39m             )\n\u001b[32m   7171\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(by) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7172\u001b[39m             keys = [self._get_label_or_level_values(x, axis=axis) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m by]\n\u001b[32m   7173\u001b[39m \n\u001b[32m   7174\u001b[39m             \u001b[38;5;66;03m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[32m   7175\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/Heriot-Watt University Team Dropbox/RES_EPS_EMQL/projects/multi-parameter-estimation/.venv/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'detector_a_time_tag'"
     ]
    }
   ],
   "source": [
    "def load_coincidences(data_dir):\n",
    "    coincidences = pd.read_csv(os.path.join(data_folder, data_dir, \"coincidences.csv\"))\n",
    "    coincidences[\"data_dir\"] = data_dir\n",
    "    return coincidences\n",
    "\n",
    "coincidences_df = pd.concat([load_coincidences(d) for d in data_dirs], ignore_index=True)\n",
    "coincidences_df = coincidences_df.sort_values(by=[\"data_dir\", \"detector_a_time_tag\"])\n",
    "coincidences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d857c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /home/jh115/Heriot-Watt University Team Dropbox/RES_EPS_EMQL/projects/multi-parameter-estimation/multi-parameter-estimation/data/2025-06-02--17h-06m-16s/coincidences.csv\n",
      "Saved /home/jh115/Heriot-Watt University Team Dropbox/RES_EPS_EMQL/projects/multi-parameter-estimation/multi-parameter-estimation/data/2025-06-02--17h-07m-37s/coincidences.csv\n",
      "Saved /home/jh115/Heriot-Watt University Team Dropbox/RES_EPS_EMQL/projects/multi-parameter-estimation/multi-parameter-estimation/data/2025-06-02--17h-07m-47s/coincidences.csv\n",
      "Saved /home/jh115/Heriot-Watt University Team Dropbox/RES_EPS_EMQL/projects/multi-parameter-estimation/multi-parameter-estimation/data/2025-06-02--17h-07m-56s/coincidences.csv\n",
      "Saved /home/jh115/Heriot-Watt University Team Dropbox/RES_EPS_EMQL/projects/multi-parameter-estimation/multi-parameter-estimation/data/2025-06-02--17h-08m-05s/coincidences.csv\n",
      "Saved /home/jh115/Heriot-Watt University Team Dropbox/RES_EPS_EMQL/projects/multi-parameter-estimation/multi-parameter-estimation/data/2025-06-02--17h-08m-19s/coincidences.csv\n"
     ]
    }
   ],
   "source": [
    "# save the dataframes to csv files based on the data_dir\n",
    "for data_dir in data_dirs:\n",
    "    df_subset = coincidences_df[coincidences_df[\"data_dir\"] == data_dir]\n",
    "    if not df_subset.empty:\n",
    "        output_file = os.path.join(data_folder, data_dir, \"coincidences.csv\")\n",
    "        df_subset.to_csv(output_file, index=False)\n",
    "        print(f\"Saved {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
